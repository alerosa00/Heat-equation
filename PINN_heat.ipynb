{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f59b9-e624-49ab-8cea-e83e98c483b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baf80c-5afa-40e4-9e29-714adde4c7a8",
   "metadata": {},
   "source": [
    "<h3>Geometry</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a66b7-e08e-4e56-85cc-3c2e2f7b3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# PINN DEFAULT SETTING :\n",
    "PDE_batch_size = 4096\n",
    "IC_batch_size  = 4096\n",
    "BC_batch_size  = 1024\n",
    "\n",
    "# Initial/Boundary condition voltage\n",
    "V0 = 1\n",
    "\n",
    "# GEOMETRY\n",
    "x_min = -1\n",
    "x_max = 1\n",
    "y_min = -1\n",
    "y_max = 1\n",
    "z_min = -1.5\n",
    "z_max = 1.5\n",
    "factor_x, factor_y, factor_z = x_max-x_min, y_max-y_min, z_max-z_min\n",
    "\n",
    "t_min = 0\n",
    "t_max = 10\n",
    "factor_t = t_max-t_min\n",
    "c_time_err = 1e-2\n",
    "logt_min = np.log(t_min + c_time_err)\n",
    "logt_max = np.log(t_max + c_time_err)\n",
    "factor_logt = logt_max-logt_min\n",
    "\n",
    "\n",
    "flag_norm_log = True\n",
    "\n",
    "if flag_norm_log == True:\n",
    "    # with log-transform\n",
    "    def Norm_time(time_coords):\n",
    "        if isinstance(time_coords, torch.Tensor):\n",
    "            return ( torch.log( time_coords + c_time_err ) ) / factor_logt\n",
    "        else:\n",
    "            return ( np.log( time_coords + c_time_err ) ) / factor_logt\n",
    "            \n",
    "    def Inv_Norm_time(norm_time_coords):\n",
    "        if isinstance(norm_time_coords, torch.Tensor):\n",
    "            return ( torch.exp(norm_time_coords * factor_logt ) - c_time_err )\n",
    "        else:\n",
    "            return ( np.exp(norm_time_coords * factor_logt ) - c_time_err )\n",
    "else:\n",
    "    # with linear-transform\n",
    "    def Norm_time(time_coords):\n",
    "        if isinstance(time_coords, torch.Tensor):\n",
    "            return time_coords / factor_t\n",
    "        else:\n",
    "            return time_coords / factor_t\n",
    "    \n",
    "    def Inv_Norm_time(norm_time_coords):\n",
    "        if isinstance(norm_time_coords, torch.Tensor):\n",
    "            return norm_time_coords * factor_t\n",
    "        else:\n",
    "            return norm_time_coords * factor_t\n",
    "\n",
    "\n",
    "norm_t_min, norm_t_max = Norm_time(t_min), Norm_time(t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c706d5-5765-41a0-91d4-5bf401f8994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error of normalization:\")\n",
    "print(Norm_time(Inv_Norm_time(2)) - 2)\n",
    "print(Inv_Norm_time(Norm_time(2)) - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549aa6d2-6022-4c0e-8d4b-69f01dd8aa80",
   "metadata": {},
   "source": [
    "<h1>PINN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f91aad-d986-47b8-b937-fc2f12f29b4e",
   "metadata": {},
   "source": [
    "<h3>Initial & Boundary conditions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49d53e-44b4-4659-8c71-645de46c70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== IC ====\n",
    "def gen_IC_points(n_points=IC_batch_size):\n",
    "    n_points = n_points//2\n",
    "    t_coords = norm_t_min * torch.ones(n_points, 1, device=device)\n",
    "    x_coords = x_min + (x_max - x_min) * torch.rand(n_points, 1, device=device)\n",
    "    y_coords = y_min + (y_max - y_min) * torch.rand(n_points, 1, device=device)\n",
    "    z_coords = z_min + (z_max - z_min) * torch.rand(n_points, 1, device=device)\n",
    "    points = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "    values = torch.sin(torch.pi*((z_coords-z_min)/(z_max-z_min)))\n",
    "    return points, values\n",
    "\n",
    "def compute_IC_loss(model, n_points=IC_batch_size, loss_function=nn.MSELoss()):\n",
    "    coords, values = gen_IC_points(n_points)\n",
    "    coords.requires_grad = True\n",
    "    values_pred = model.forward(coords)\n",
    "    loss = loss_function( values_pred, values )\n",
    "    return loss\n",
    "\n",
    "# ==== BC ====\n",
    "def gen_BC_points(n_points=BC_batch_size):\n",
    "    t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(n_points, 1, device=device)\n",
    "    x_coords = x_min + (x_max - x_min) * torch.rand(n_points, 1, device=device)\n",
    "    y_coords = y_min + (y_max - y_min) * torch.rand(n_points, 1, device=device)\n",
    "    # z_min BC\n",
    "    z_coords = z_min * torch.ones(n_points, 1, device=device)\n",
    "    points2 = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "    values2 = torch.zeros_like(z_coords, device=device)\n",
    "    # z_max BC\n",
    "    z_coords = z_max * torch.ones(n_points, 1, device=device)\n",
    "    points3 = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "    values3 = torch.zeros_like(z_coords, device=device)\n",
    "    points = torch.cat([points2, points3], dim=0)\n",
    "    values = torch.cat([values2, values3], dim=0)\n",
    "    return points, values\n",
    "\n",
    "def compute_BC_loss(model, n_points=BC_batch_size, loss_function=nn.MSELoss()):\n",
    "    coords, values = gen_BC_points(n_points)\n",
    "    coords.requires_grad = True\n",
    "    values_pred = model.forward(coords)\n",
    "    loss = loss_function( values_pred, values )\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ==== PLOTS ====\n",
    "\n",
    "# IC PLOTs\n",
    "points, IC_values = gen_IC_points(10000)\n",
    "# plane XZ\n",
    "x_coords = points[:,1]\n",
    "z_coords = points[:,3]\n",
    "x_coords = x_coords.detach().cpu().numpy()\n",
    "z_coords = z_coords.detach().cpu().numpy()\n",
    "IC_values = IC_values.detach().cpu().numpy()\n",
    "# plots\n",
    "fig = plt.scatter(x_coords, z_coords, c=IC_values, s=2)\n",
    "plt.title(\"Initial condition\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.colorbar(fig)\n",
    "plt.show()\n",
    "# plots\n",
    "fig = plt.scatter(z_coords, IC_values, s=2)\n",
    "plt.title(\"Initial condition\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.show()\n",
    "\n",
    "# BC PLOTs\n",
    "points, BC_values = gen_BC_points(10000)\n",
    "# plane XZ\n",
    "x_coords = points[:,1]\n",
    "z_coords = points[:,3]\n",
    "x_coords = x_coords.detach().cpu().numpy()\n",
    "z_coords = z_coords.detach().cpu().numpy()\n",
    "BC_values = BC_values.detach().cpu().numpy()\n",
    "# plots\n",
    "fig = plt.scatter(x_coords, z_coords, c=BC_values, s=2, vmin=0, vmax=V0)\n",
    "plt.title(\"Boundary condition\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.colorbar(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95986bf5-dea9-40de-ae9f-72172e79b8b9",
   "metadata": {},
   "source": [
    "<h3>PDE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbbdf1-6683-4fc2-81cc-2f04979c8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HEAT EQUATION\n",
    "class QSM_PDE_heat:       \n",
    "\n",
    "    def gen_PDE_points(self, n_points=PDE_batch_size):\n",
    "        t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(n_points, 1, device=device)\n",
    "        x_coords = x_min + (x_max - x_min) * torch.rand(n_points, 1, device=device)\n",
    "        y_coords = y_min + (y_max - y_min) * torch.rand(n_points, 1, device=device)\n",
    "        z_coords = z_min + (z_max - z_min) * torch.rand(n_points, 1, device=device)\n",
    "        points = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "        return points\n",
    "\n",
    "    \n",
    "    def compute_PDE(self, coords, pred_func, flag_norm_log=True):\n",
    "        u = pred_func[:,0]\n",
    "        u_t  = self.get_derivative(pred_func, coords, 1)[:,0]\n",
    "        u_x  = self.get_derivative(pred_func, coords, 1)[:,1]\n",
    "        u_xx = self.get_derivative(u_x, coords, 1)[:,1]\n",
    "        u_y  = self.get_derivative(pred_func, coords, 1)[:,2]\n",
    "        u_yy = self.get_derivative(u_y, coords, 1)[:,2]\n",
    "        u_z  = self.get_derivative(pred_func, coords, 1)[:,3]\n",
    "        u_zz = self.get_derivative(u_z, coords, 1)[:,3]\n",
    "        Delta_u = u_xx + u_yy + u_zz\n",
    "        if flag_norm_log == True:\n",
    "            # with log-transform\n",
    "            factorrr = ( torch.exp(coords[:,0]*factor_logt ) * factor_logt )\n",
    "            eq = u_t - Delta_u * factorrr\n",
    "        else:\n",
    "            # without log-transform\n",
    "            eq = u_t - Delta_u * factor_t\n",
    "        return eq\n",
    "\n",
    "    \n",
    "    def get_derivative(self, y, x, n: int = 1):\n",
    "        \"\"\"\n",
    "            compute n-times 1D derivatives of y along x-direction\n",
    "        \"\"\"\n",
    "        if n == 0:\n",
    "            return y\n",
    "        else:\n",
    "            dy_dx = torch.autograd.grad(y, x, torch.ones_like(y).to(y.device), create_graph=True, retain_graph=True, allow_unused=True)[0]              \n",
    "        return self.get_derivative(dy_dx, x, n - 1)\n",
    "\n",
    "    \n",
    "    def compute_PDE_loss(self, model, n_points=PDE_batch_size, loss_function=nn.MSELoss(), flag_norm_log=True):\n",
    "        coords = self.gen_PDE_points(n_points=n_points)\n",
    "        coords.requires_grad = True\n",
    "        values_pred = model.forward(coords)\n",
    "        pde_pred = self.compute_PDE(coords, values_pred, flag_norm_log=flag_norm_log)\n",
    "        loss = loss_function( pde_pred, torch.zeros_like(pde_pred, dtype=torch.float32, device=device) )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6cc6c-9b13-42f3-b016-304df70a465f",
   "metadata": {},
   "source": [
    "<h3>PINN model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c2cc3-2af4-40a3-9638-84eca2b28930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_model(nn.Module):\n",
    "   \n",
    "    def __init__(self, input_dim, n_nodes, n_layers, n_batches, dropout):\n",
    "        super().__init__()\n",
    "        # PDE part\n",
    "        self._PDE = QSM_PDE_heat()\n",
    "        self.history = []\n",
    "        # DNN part\n",
    "        self.n_batches = n_batches\n",
    "        self.dropout   = dropout\n",
    "        layers = [nn.Linear(input_dim, n_nodes), nn.Tanh(), nn.Dropout(self.dropout)]\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(nn.Linear(n_nodes, n_nodes))\n",
    "            layers.append(nn.Tanh())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "        layers.append(nn.Linear(n_nodes, 1))\n",
    "        layers.append(nn.Tanh())\n",
    "        # network\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        # initialization of NN\n",
    "        for layer in self.network:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_normal_(layer.weight, gain=1.0)\n",
    "                init.zeros_(layer.bias)\n",
    "\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        return self.network(coords)\n",
    "                \n",
    "\n",
    "    def store_training_df(self, history, epochs):\n",
    "        training_loss = history[:,4] * history[:,0] + history[:,5] * history[:,1] + history[:,8] * history[:,9]\n",
    "        validation_loss = history[:,4] * history[:,2] + history[:,5] * history[:,3] + history[:,8] * history[:,10]\n",
    "        df_train = pd.DataFrame(\n",
    "            {\n",
    "                \"epochs\"            : [ e for e in range(epochs) ],\n",
    "                \"training_loss\"     : training_loss,\n",
    "                \"validation_loss\"   : validation_loss,\n",
    "                'lr'                : history[:,7],\n",
    "                \"IC_train_losses\"   : history[:,0],\n",
    "                \"BC_train_losses\"   : history[:,9],\n",
    "                \"PDE_train_losses\"  : history[:,1],\n",
    "                \"weight_IC\"         : history[:,4],\n",
    "                \"weight_BC\"         : history[:,8],\n",
    "                \"weight_PDE\"        : history[:,5]\n",
    "            }\n",
    "        )\n",
    "        df_train.to_csv(f'history_training_plane.csv')\n",
    "        torch.save(self.state_dict(), \"end_plane_model.pth\")      \n",
    "\n",
    "    \n",
    "    def train_model(self, optimizer, patience = 10, loss_function = nn.MSELoss(), epochs = 200, validation_split = 0.1):\n",
    "        print(\"Start :\")\n",
    "        start_time = time.time()   \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=patience)\n",
    "        # number of batches for training and validation\n",
    "        n_train_batches = int( (1 - validation_split) * n_batches)\n",
    "        n_val_batches   = n_batches - n_train_batches\n",
    "        print(f\"  number of epochs             : {epochs}\")\n",
    "        print(f\"  number of train batches      : {n_train_batches}\")\n",
    "        print(f\"  number of validation batches : {n_val_batches}\")\n",
    "        print(\" \")        \n",
    "        print(\"Training in progress...\")\n",
    "        print(\" \")\n",
    "\n",
    "        weight_IC, weight_BC, weight_PDE = 1, 1, 1\n",
    "        # EPOCHS\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            # === TRAINING STEP ===\n",
    "            self.train()\n",
    "            start_tr = time.time()\n",
    "            IC_total_loss, BC_total_loss, PDE_total_loss = 0, 0, 0            \n",
    "            for indx_batch in range(n_train_batches):\n",
    "                optimizer.zero_grad()\n",
    "                IC_loss  = compute_IC_loss(model=self)\n",
    "                BC_loss  = compute_BC_loss(model=self)\n",
    "                PDE_loss = self._PDE.compute_PDE_loss(model=self)\n",
    "                Loss = weight_IC * IC_loss + weight_BC * BC_loss + weight_PDE * PDE_loss\n",
    "                Loss.backward()\n",
    "                optimizer.step()\n",
    "                IC_total_loss   += IC_loss.item()\n",
    "                BC_total_loss   += BC_loss.item()\n",
    "                PDE_total_loss  += PDE_loss.item()\n",
    "            IC_total_loss  /= n_train_batches\n",
    "            BC_total_loss  /= n_train_batches\n",
    "            PDE_total_loss /= n_train_batches\n",
    "            end_tr = time.time()\n",
    "\n",
    "            # === VALIDATION STEP ===\n",
    "            self.eval()\n",
    "            start_val = time.time()\n",
    "            IC_val_loss, BC_val_loss, PDE_val_loss = 0, 0, 0  \n",
    "            for indx_batch in range(n_val_batches):\n",
    "                optimizer.zero_grad()\n",
    "                IC_val_loss  += (compute_IC_loss(model=self) ).item()\n",
    "                BC_val_loss  += ( compute_BC_loss(model=self) ).item()\n",
    "                PDE_val_loss += ( self._PDE.compute_PDE_loss(model=self) ).item()\n",
    "            IC_val_loss   /= n_val_batches\n",
    "            BC_val_loss   /= n_val_batches\n",
    "            PDE_val_loss  /= n_val_batches\n",
    "            scheduler.step( weight_IC * IC_val_loss + weight_BC * BC_val_loss + weight_PDE * PDE_val_loss )\n",
    "            end_val = time.time()\n",
    "            \n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "            lambda_eff = weight_PDE/np.maximum(weight_IC,1e-8) * PDE_total_loss/np.maximum(IC_total_loss,1e-8)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            # === PRINT LOSSES ===\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            print(f\"  Training losses   ==>  IC: {IC_total_loss} - BC: {BC_total_loss} - pde: {PDE_total_loss}\")\n",
    "            print(f\"  Validation losses ==>  IC: {IC_val_loss} - BC: {BC_val_loss} - PDE: {PDE_val_loss}\")\n",
    "            print(f\"  time : {end - start} s  - train: {end_tr - start_tr} s  - val: {end_val - start_val} s\")\n",
    "            print(f\"     ( w_IC : {weight_IC} - w_BC : {weight_IC} - w_PDE : {weight_PDE} - lambda_eff : {lambda_eff} )\")\n",
    "            print(f\"     ( learning rate : {current_lr} )\")\n",
    "            self.history.append([ IC_total_loss, PDE_total_loss, IC_val_loss, PDE_val_loss,\n",
    "                            weight_IC, weight_PDE, lambda_eff, current_lr, weight_BC, BC_total_loss, BC_val_loss ])\n",
    "            print(f\" \")\n",
    "            print(f\" \")\n",
    "            \n",
    "\n",
    "        # END EPOCHS\n",
    "        self.store_training_df(np.array(self.history), epochs)\n",
    "        print(f\"Done!  (time : {time.time() - start_time})\")\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef57c1-306e-4378-bae3-2131b01d6d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construction of PINN\n",
    "model = 0\n",
    "input_dim = 4     # (t, x, y, z)\n",
    "n_nodes = 64\n",
    "n_layers = 4\n",
    "n_batches = 32\n",
    "dropout = 0\n",
    "model = PINN_model( input_dim, n_nodes, n_layers, n_batches, dropout ).to(device)\n",
    "\n",
    "# training of PINN\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-9)\n",
    "loss_function = nn.MSELoss()\n",
    "history = model.train_model(optimizer, patience=100, loss_function=loss_function, epochs=1000)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# PLOTS OF TRAINING AND VALIDATION STEPS\n",
    "# plot IC\n",
    "plt.plot([pair[0] for pair in history], label=\"Training\")\n",
    "plt.plot([pair[2] for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"IC error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plot BC\n",
    "plt.plot([pair[9] for pair in history], label=\"Training\")\n",
    "plt.plot([pair[10] for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"BC error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plot PDE\n",
    "plt.plot([pair[1] for pair in history], label=\"Training\")\n",
    "plt.plot([pair[3] for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"PDE error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plot LAMBDA EFFECTIVE\n",
    "plt.plot([pair[6] for pair in history], label=\"lambda eff\")\n",
    "plt.legend(title=\"Lambda effective\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plot LEARNING RATE\n",
    "plt.plot([pair[7] for pair in history], label=\"lr\")\n",
    "plt.legend(title=\"Learning rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de61fb-0f44-4d56-b82d-11bc54737cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION of V using PINN model\n",
    "sampled_times = np.linspace( norm_t_min, norm_t_max, 6 )\n",
    "sampled_x = (x_max + x_min) / 2\n",
    "sampled_y = (y_max + y_min) / 2\n",
    "n_samples = 20000\n",
    "plt.figure(figsize=(16,4))\n",
    "model.eval()\n",
    "pde_class = QSM_PDE_heat()\n",
    "\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = pde_class.gen_PDE_points(n_samples)\n",
    "    X_pred[:,0] = n_t * torch.ones_like(X_pred[:,0], device=device)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    # predicted result\n",
    "    with torch.no_grad():\n",
    "        V_pred = model.forward(X_pred)\n",
    "    V_pred = V_pred.detach().cpu().numpy()\n",
    "    \n",
    "    plt.subplot(1, len(sampled_times), i_plot)\n",
    "    plt.title(f\"Pred {real_t:.5f} ns\")\n",
    "    im0=plt.scatter(X_Sample[:, 1], X_Sample[:, 3], c=V_pred, s=2, cmap='plasma', vmin=0, vmax=1)\n",
    "    plt.ylabel(\"z\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.colorbar(im0)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_heat.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Settings ===\n",
    "sampled_times = norm_t_min + (norm_t_max - norm_t_min) * np.linspace(0, 1, 12)\n",
    "plt.figure(figsize=(8, 3 * len(sampled_times)))\n",
    "model.eval()\n",
    "pde_class = QSM_PDE_heat()\n",
    "\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = pde_class.gen_PDE_points(n_samples)\n",
    "    X_pred[:, 0] = n_t * torch.ones_like(X_pred[:, 0], device=device)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        V_pred = model.forward(X_pred)\n",
    "    V_pred = V_pred.detach().cpu().numpy().squeeze()\n",
    "    ax_left = plt.subplot(len(sampled_times), 2, 2 * i_plot - 1)\n",
    "    im0 = ax_left.scatter(X_Sample[:, 1], X_Sample[:, 3], c=V_pred, s=2, cmap='plasma', vmin=0, vmax=1)\n",
    "    ax_left.set_title(f\"t = {real_t:.2f} ns\\nV(x,z)\")\n",
    "    ax_left.set_xlabel(\"x\")\n",
    "    ax_left.set_ylabel(\"z\")\n",
    "    plt.colorbar(im0, ax=ax_left)\n",
    "\n",
    "    X_pred[:, 1] = sampled_x * torch.ones_like(X_pred[:, 0], device=device)\n",
    "    X_pred[:, 2] = sampled_y * torch.ones_like(X_pred[:, 0], device=device)\n",
    "    X_pred[:, 3] = torch.linspace(z_min, z_max, len(X_pred[:,0]))\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        V_pred = model.forward(X_pred)\n",
    "    V_pred = V_pred.detach().cpu().numpy().squeeze()\n",
    "    ax_right = plt.subplot(len(sampled_times), 2, 2 * i_plot)\n",
    "    ax_right.plot(X_Sample[:,3], V_pred)\n",
    "    ax_right.set_title(f\"V(z) at x={sampled_x:.2f}, y={sampled_y:.2f}\")\n",
    "    ax_right.set_xlabel(\"z\")\n",
    "    ax_right.set_ylabel(\"V\")\n",
    "    ax_right.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_heat2.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nVidia Modulus",
   "language": "python",
   "name": "modulus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
